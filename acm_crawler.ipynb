{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACM CRAWLER\n",
    "Jupyter Notebook to crawl the ACM digital library for publications containing links to repositories hosted on GitHub  \n",
    "For a repeated execution of the crawling process, the kernel has to be restarted, otherwise a ReactorNotRestartable error is thrown (https://github.com/scrapy/scrapy/issues/2594)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import yaml\n",
    "import scrapy\n",
    "import time\n",
    "import w3lib.html\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crawling started at 30.09.2020:\n",
    "crawling higher than start page 40 (limited to 2000 results): \n",
    "\"In order to show you the most relevant results, \n",
    "we have omitted some entries very similar to the 2000 already displayed.\n",
    "Please refine the results either via the facet filters on the left or edit \n",
    "your search in Advanced Search via the button at the top.\"\"\n",
    "To manage the quantity of publications\n",
    "in the search period from 2008 until 2020\n",
    "search intervals are defined. Depending on \n",
    "the number of results, for each year is at \n",
    "least one start url specified.   \n",
    "0 Results for: [All: github.com] AND [Publication Date: (01/01/1936 TO 12/31/2007)] (therefore search starts in 2008)  \n",
    "results for 2008 to 2012: 586 (crawled: 586, total: 586)  \n",
    "results for 2013: 705 (crawled: 705, total: 1291)  \n",
    "results for 2014: 1,163 (crawled: 1163, total: 2454)  \n",
    "results for 2015: 1,900 (crawled: 1900, total: 4354)  \n",
    "results for 01.2016 to 06.2016: 1,228 (crawled: 1228, total: 5582)  \n",
    "results for 07.2016 to 09.2016: 740 (crawled: 740, total: 6322)  \n",
    "results for 10.2016 to 12.2016: 855 (crawled: 855, total: 7177)  \n",
    "results for 01.2017 to 03.2017: 534 (crawled: 534, total: 7711)  \n",
    "results for 04.2017 to 06.2017: 912 (crawled: 912, total: 8623)  \n",
    "results for 07.2017 to 09.2017: 1,099 (crawled: 1099, total: 9722)  \n",
    "results for 10.2017 to 12.2017: 1,175  (crawled: 1175, total: 10897)  \n",
    "results for 01.2018 to 03.2018: 648 (crawled: 648, total: 11545)  \n",
    "results for 04.2018 to 06.2018: 1,201 (crawled: 1201, total: 12746)  \n",
    "results for 07.2018 to 09.2018: 1,106 (crawled: 1106, total: 13852)  \n",
    "results for 10.2018 to 12.2018: 1,364 (crawled: 1364, total: 15216)  \n",
    "results for 01.2019 to 03.2019: 700 (crawled: 700, total: 15916)  \n",
    "results for 04.2019 to 06.2019: 1,415 (crawled: 1415, total: 17331)  \n",
    "results for 07.2019 to 09.2019: 1,353 (crawled: 1353, total: 18684)  \n",
    "results for 10.2019 to 12.2019: 1,239 (crawled: 1239, total: 19923)  \n",
    "results for 01.2020 to 03.2020: 653 (crawled: 653, total: 20576)  \n",
    "results for 04.2020 to 06.2020: 1,163 (crawled: 1163, total: 21739)  \n",
    "results for 07.2020 to 09.2020: 1,064 (crawled: 1064, total: 22803)  \n",
    "results for 10.2020: 22 (crawled: 22, total: 22825) \n",
    "results for 10.2020: 818 (crawled: 818, total: 23643)\n",
    "results for 11.2020 to 12.2020: 597 (crawled: 597, total: 24240)\n",
    "total results: 22,852  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpiderACM(scrapy.Spider):\n",
    "    \n",
    "    name = 'SpiderACM'\n",
    "    \n",
    "    custom_settings = {\n",
    "        'METAREFRESH_ENABLED' : False\n",
    "    }\n",
    "\n",
    "    start_urls = [\n",
    "        # processed:\n",
    "        # 'https://dl.acm.org/action/doSearch?AllField=github.com&pageSize=50&AfterYear=2008&BeforeYear=2012&expand=all'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=1&AfterYear=2013&BeforeMonth=12&BeforeYear=2013&AllField=github.com&startPage=0&pageSize=50'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=1&AfterYear=2014&BeforeMonth=12&BeforeYear=2014&AllField=github.com&startPage=0&pageSize=50'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=1&AfterYear=2015&BeforeMonth=12&BeforeYear=2015&AllField=github.com&startPage=0&pageSize=50'\n",
    "        # last site with 50 results was not indicated on page 36, therefore the following extra request:\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=1&AfterYear=2015&BeforeMonth=12&BeforeYear=2015&AllField=github.com&startPage=37&pageSize=50'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=1&AfterYear=2016&BeforeMonth=6&BeforeYear=2016&AllField=github.com&pageSize=50'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=7&AfterYear=2016&BeforeMonth=9&BeforeYear=2016&AllField=github.com&startPage=0&pageSize=50'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=10&AfterYear=2016&BeforeMonth=12&BeforeYear=2016&AllField=github.com&startPage=0&pageSize=50'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=1&AfterYear=2017&BeforeMonth=3&BeforeYear=2017&AllField=github.com&startPage=0&pageSize=50'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=4&AfterYear=2017&BeforeMonth=6&BeforeYear=2017&AllField=github.com&startPage=0&pageSize=50'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=7&AfterYear=2017&BeforeMonth=9&BeforeYear=2017&AllField=github.com&startPage=0&pageSize=50'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=10&AfterYear=2017&BeforeMonth=12&BeforeYear=2017&AllField=github.com&startPage=0&pageSize=50'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=1&AfterYear=2018&BeforeMonth=3&BeforeYear=2018&AllField=github.com&startPage=0&pageSize=50'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=4&AfterYear=2018&BeforeMonth=6&BeforeYear=2018&AllField=github.com&startPage=0&pageSize=50'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=7&AfterYear=2018&BeforeMonth=9&BeforeYear=2018&AllField=github.com&startPage=0&pageSize=50'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=10&AfterYear=2018&BeforeMonth=12&BeforeYear=2018&AllField=github.com&startPage=0&pageSize=50'\n",
    "        #'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=1&AfterYear=2019&BeforeMonth=3&BeforeYear=2019&AllField=github.com&startPage=0&pageSize=50'\n",
    "        # last page not in pagination\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=1&AfterYear=2019&BeforeMonth=3&BeforeYear=2019&AllField=github.com&startPage=13&pageSize=50'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=4&AfterYear=2019&BeforeMonth=6&BeforeYear=2019&AllField=github.com&startPage=0&pageSize=50'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=7&AfterYear=2019&BeforeMonth=9&BeforeYear=2019&AllField=github.com&startPage=0&pageSize=50'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=10&AfterYear=2019&BeforeMonth=12&BeforeYear=2019&AllField=github.com&startPage=0&pageSize=50'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=1&AfterYear=2020&BeforeMonth=3&BeforeYear=2020&AllField=github.com&startPage=0&pageSize=50'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=4&AfterYear=2020&BeforeMonth=6&BeforeYear=2020&AllField=github.com&startPage=0&pageSize=50'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=7&AfterYear=2020&BeforeMonth=9&BeforeYear=2020&AllField=github.com&startPage=0&pageSize=50'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=10&AfterYear=2020&BeforeMonth=10&BeforeYear=2020&AllField=github.com&startPage=0&pageSize=50'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=10&AfterYear=2020&BeforeMonth=10&BeforeYear=2020&AllField=github.com&startPage=0&pageSize=50'\n",
    "        # 'https://dl.acm.org/action/doSearch?fillQuickSearch=false&expand=all&AfterMonth=11&AfterYear=2020&BeforeMonth=12&BeforeYear=2020&AllField=github.com&startPage=0&pageSize=50'\n",
    "        # next:\n",
    "    ]\n",
    "    \n",
    "    USER_AGENT='Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:55.0) Gecko/20100101 Firefox/80.0'\n",
    "    \n",
    "    def parse(self, response):\n",
    "        \n",
    "        selectors = response.xpath('//div[has-class(\"issue-item__content\")]')\n",
    "        for sel in selectors: \n",
    "            full_text = ''\n",
    "            summary = ''\n",
    "            doi = ''\n",
    "            title = (sel.xpath('.//span[has-class(\"hlFld-Title\")]/a/text()').get())\n",
    "            doi_from_link = (sel.xpath('.//span[has-class(\"hlFld-Title\")]/a/@href').get()).replace('/doi/', '')\n",
    "            link = 'https://dl.acm.org' + sel.xpath('.//span[has-class(\"hlFld-Title\")]/a/@href').get()\n",
    "            published = sel.xpath('.//span[has-class(\"dot-separator\")]/span[1]/text()').get()\n",
    "            journal_ref = (sel.xpath('.//span[has-class(\"epub-section__title\")]/text()').get())\n",
    "            doi_url = sel.xpath('.//a[has-class(\"issue-item__doi dot-separator\")]/text()').get()\n",
    "            pdf_url = sel.xpath('.//a[has-class(\"btn--icon simple-tooltip__block--b red btn\")]/@href').get()\n",
    "            abstract =  sel.xpath('.//div[has-class(\"abstract-text\")]/p').extract()\n",
    "            cited = sel.xpath('.//span[has-class(\"citation\")]/span/text()').extract()\n",
    "            downloads = sel.xpath('.//span[has-class(\"metric\")]/span/text()').extract()            \n",
    "            \n",
    "            if pdf_url:\n",
    "                pdf_url = 'https://dl.acm.org' + pdf_url\n",
    "\n",
    "            if doi_url:\n",
    "                doi_url = w3lib.html.remove_tags(doi_url).replace(\"\\n\",\"\")\n",
    "                doi = doi_url.rsplit('doi.org/', 1)[1]\n",
    "                \n",
    "            # cosmetic corrections, title may be None\n",
    "            if title and '\\n                     ' in title:\n",
    "                    title = title.replace('\\n                     ', ' ')\n",
    "            if journal_ref and '\\n                     ' in journal_ref:\n",
    "                journal_ref = journal_ref.replace('\\n                     ', ' ')\n",
    "            if published:\n",
    "                published = published.replace(', ','')\n",
    "             \n",
    "            # abstract segment from the highlights box\n",
    "            if len(abstract):\n",
    "                summary = w3lib.html.remove_tags(abstract[0])\n",
    "            \n",
    "            # full_text segment from the highlights box\n",
    "            listing = sel.xpath('.//div[has-class(\"full-text\")]/p').extract()\n",
    "            for p in listing:\n",
    "                full_text = full_text + p\n",
    "            if full_text:\n",
    "                full_text = w3lib.html.remove_tags(full_text)\n",
    "            \n",
    "            post = {'source': 'acm',\n",
    "                    'request_date': datetime.now(),\n",
    "                    'arxiv_id': None,\n",
    "                    'doi': doi,\n",
    "                    'doi_from_link': doi_from_link,\n",
    "                    'title': title,\n",
    "                    'published': published,\n",
    "                    'updated': None,\n",
    "                    'url' : link,\n",
    "                    'doi_url': doi_url,\n",
    "                    'pdf_url': pdf_url,\n",
    "                    'primary_category': None,\n",
    "                    'all_categories' : None,\n",
    "                    'journal_ref' : journal_ref,\n",
    "                    'total_citations': cited,\n",
    "                    'total_downloads': downloads,\n",
    "                    'summary': summary,\n",
    "                    'full_text_extract': full_text\n",
    "                   }  \n",
    "            # no duplicate check as titles and dois may be None\n",
    "            db.insert_one(post)\n",
    "            \n",
    "        next_page = response.xpath('//a[has-class(\"pagination__btn--next\")]/@href').get()\n",
    "        if (next_page is not None) and ('startPage=40' not in next_page):\n",
    "            time.sleep(180)\n",
    "            yield response.follow(next_page, callback=self.parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\", 'r') as stream:\n",
    "    try:\n",
    "        params = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "db = getattr(getattr(MongoClient(), params['database']['name']), params['database']['collections']['publications'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = CrawlerProcess()\n",
    "process.crawl(SpiderACM)\n",
    "process.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
