{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Mining Source Code Repositories***    \n",
    "*Goal*: harvest repositories containing specified keywords    \n",
    "*Supported code collaboration and version control tools*: GitHub  \n",
    "\n",
    "*Default Parameters in the configuration file*:  \n",
    "  - repo_sources: github\n",
    "  - repo_keywords: doi+10, doi+10+in:readme\n",
    "  - start_date: \"2008-01-01\"\n",
    "  - end_date: \"2020-10-01\"\n",
    "  - delta: days=7\n",
    "  - search_repos\n",
    "  - readme   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from datetime import datetime\n",
    "import yaml\n",
    "from modules.database import RepoCollection\n",
    "from modules.github_harvester import GitHubHarvester\n",
    "from IPython.display import clear_output, display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Required Parameter**  \n",
    "All neccessary parameter for the repository harvesting process are specified in the associated configuration file, located in the same folder. The specified repository hosting services are checked against the supported services. A notification about skipping unsupported services is printed. Also services, that require an authentication token and the corresponding token is not specified, are skipped. The indicated authentication tokens are stored in the corresponding dictionary entry.   \n",
    "The MongoDB database is used to store the metadata and additional information of the harvested repositories. If the given database table does not exist, it has to be confirmed whether a new database table with this name should be created or an alternative database table may be specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = []\n",
    "\n",
    "# load parameters from the config file\n",
    "with open(\"config.yaml\", 'r') as stream:\n",
    "    params = yaml.safe_load(stream)\n",
    "\n",
    "# check whether the specified sources are supported and, \n",
    "# if required, an authentication token is given \n",
    "for param in params['repo_sources']:\n",
    "    if param not in params['supported_sources']:\n",
    "        print(\"excluded, as not supported: \", param)\n",
    "    elif (params['supported_sources'][param]['token_required'] == 'true' \n",
    "          and not params['authentication'][param]):\n",
    "        print(\"excluded, as token is needed: \", param)\n",
    "    else:\n",
    "        sources.append(param)\n",
    "\n",
    "# check if database table exists\n",
    "repo_collection = RepoCollection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Harvesting Repositories**  \n",
    "The configuration file contains two flags indicating whether the repository metadata and readme files should be harvested. At the beginning, this flag is checked for the metadata harvesting. For each repository hosting service (source) the associated harvester class is instantiated. The search process iterates over all specified keywords. As the number of search results exceeds the number of returned results (limited to 1000), the search period is splitted into search intervals, whose length may be defined in the configuration file.   \n",
    "After requesting the repositories, the metadata are stored in the database table. Due to the overlapping search terms, repositories may be returned twice. In the case, that a repository already is inserted, the current keyword is added to the repository's keyword list. If no entry for the repository exists, its metadata will be inserted in combination with additional information, like the harvesting date, its hosting service, and the associated search term.   \n",
    "The GitHub REST API limits the number of search results to 1,000, grouped into maximum ten pages with maximum 100 repositories. The HTTPs header contains the URL of the following page. This link is extracted and reuqested.  \n",
    "After each API call the iteration is paused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'search_repos' in params['repo_harvester']:\n",
    "    for source in sources:\n",
    "\n",
    "        remaining_search_requests = -1\n",
    "        # instantiate harvester class\n",
    "        current = getattr(\n",
    "            sys.modules[__name__],\n",
    "            params['supported_sources'][source]['class'])(params['authentication'][source])\n",
    "        next_url = None\n",
    "\n",
    "        for key in params['repo_keywords']:\n",
    "            # use for start, end, and interval the parameter from the config file\n",
    "            # to create search intervals\n",
    "            for interval in current.create_interval(params['start_date'],\n",
    "                                                    params['end_date'],\n",
    "                                                    params['delta']):\n",
    "\n",
    "                while True:\n",
    "                    # progress indicator\n",
    "                    clear_output(wait=True)\n",
    "                    if next_url:\n",
    "                        print('API call: ', next_url)\n",
    "                    else:\n",
    "                        print('API call for keyword', key, 'and interval', interval)\n",
    "\n",
    "                    # request repositories\n",
    "                    response = current.get_search_results(\n",
    "                        remaining_search_requests,\n",
    "                        next_url,\n",
    "                        key,\n",
    "                        interval)\n",
    "\n",
    "                    # store metadata of each repository in db\n",
    "                    if response:\n",
    "                        for elem in response.json()['items']:\n",
    "                            repo_collection.save_repo(elem, key, source, datetime.now())\n",
    "\n",
    "                        # check whether further pages are available, and if so set next request url\n",
    "                        # link may contain first, last, prev, and next URL\n",
    "                        if 'link' in response.headers:\n",
    "                            next_url = current.get_next_page(response.headers['link'].split(\",\"))\n",
    "                        else:\n",
    "                            next_url = None\n",
    "\n",
    "                        # set the remaining rate limit\n",
    "                        remaining_search_requests = int(response.headers['X-Ratelimit-Remaining'])\n",
    "                    time.sleep(current.get_search_sleep_time())\n",
    "\n",
    "                    if not next_url:\n",
    "                        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Harvest Readme Files**  \n",
    "In addition to the repository metadata, the Readme file may be harvested. It is intended to provide the context of the specified search terms, to extract them in the further processing steps. For each repository without an existing readme field, the Readme file is requested. As the existing repositories are not sorted by their hosting services, the associated harvester class is instantiated by means of the repository source information. If a repository does not contain a Readme file the note 'empty readme' is added to the repositories entry.     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'readme' in params['repo_harvester']:\n",
    "\n",
    "    total = repo_collection.get_number_of_entries({'readme':{\"$exists\" : False}})\n",
    "    counter = 0\n",
    "    remaining_core_requests = -1\n",
    "    print('Started harvesting Readme files...')\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # progress indicator\n",
    "        counter = counter + 1\n",
    "        if counter % 100 == 0 or counter == total:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Processed {0} of {1}\".format(counter, total))\n",
    "\n",
    "        # look up one repository without a readme field\n",
    "        repo = repo_collection.get_entry({'readme':{\"$exists\" : False}})\n",
    "        if repo:\n",
    "            current = getattr(\n",
    "                sys.modules[__name__],\n",
    "                params['supported_sources'][repo['source']]['class'])(params['authentication'][repo['source']])\n",
    "        else:\n",
    "            break\n",
    "\n",
    "        # request Readme file of the repository\n",
    "        readme, remaining_core_requests = current.get_api_response('readme',\n",
    "                                                                   str(repo['id']),\n",
    "                                                                   remaining_core_requests)\n",
    "\n",
    "        # add readme content to repository entry   \n",
    "        post = {\"$set\" : {'readme': readme.text}} if readme else {\"$set\" : {'readme': 'empty readme'}}\n",
    "        repo_collection.mod_entry({'id': repo['id']}, post)\n",
    "\n",
    "        time.sleep(current.get_core_sleep_time())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_final",
   "language": "python",
   "name": "venv_final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
