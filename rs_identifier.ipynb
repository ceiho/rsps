{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Research Software Identifier***\n",
    "*Prerequisites*:\n",
    "  - MongoDB\n",
    "  - Jupyter Notebook\n",
    "  - Packages (see requirements.txt)\n",
    "  - Configuration File (in the same folder)\n",
    "\n",
    "*Getting started*:\n",
    "  - Create a virtual environment\n",
    "  - Install required packages (pip install requirements.txt)\n",
    "  - Specify parameter in the configuration file\n",
    "  - Run this Notebook\n",
    "  \n",
    "*Try on Binder*:\n",
    "  - link\n",
    "\n",
    "*Required Data* (no new data are harvested):\n",
    "  - DB table with repositories: full_name, description, readme\n",
    "  - DB table with publications: doi | arxiv_id | title, text fragments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import time\n",
    "import modules.database as db\n",
    "from datetime import date, timedelta, datetime\n",
    "import yaml\n",
    "import requests\n",
    "from IPython.display import clear_output, display\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import modules.auxiliary_functions as aux\n",
    "from modules.github_harvester import GitHubHarvester"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Required Parameter**  \n",
    "All neccessary parameters for the identification process of research software \n",
    "are specified in the configuration file, located in the same folder.\n",
    "The specified repository hosting services are checked against the\n",
    "supported services. A notification about skipping unsupported services is printed.\n",
    "Also services, that require an authentication token and the corresponding token\n",
    "is not specified, are skipped. The indicated authentication tokens are stored\n",
    "in the corresponding dictionary entry.  \n",
    "The MongoDB database is used to store the identified research software repositories\n",
    "and their corresponding publications. Both repositories and publications get their\n",
    "separate database table. To link publications and repositories, each repository has a\n",
    "list of DOI names and each publication has a list of repository names. If the given\n",
    "database tables do not exist, it has to be confirmed whether a new database table\n",
    "with this name should be created or an alternative database table may be specified.\n",
    "Only the database table for the journal subject categorization has to be present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load parameters from configuration file\n",
    "with open(\"config.yaml\", 'r') as stream:\n",
    "    params = yaml.safe_load(stream)\n",
    "\n",
    "for param in params['repo_sources']:\n",
    "    if param not in params['supported_sources']:\n",
    "        print(\"excluded, as not supported: \", param)\n",
    "    elif (params['supported_sources'][param]['token_required'] and not params['authentication'][param]):\n",
    "        print(\"excluded, as token is needed: \", param)\n",
    "\n",
    "# instantiate MongoDB database collections and check if collections exist\n",
    "repo_table = db.RepoCollection()\n",
    "publication_table = db.Collection('publications')\n",
    "rs_repo_table = db.RsRepoCollection()\n",
    "rs_publication_table = db.RsArtifactCollection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add Repositories and Publications**   \n",
    "If no data are available or the existing data should be extended,\n",
    "the comment sign before the parameters new_repositories and new_publications \n",
    "can be removed and the corresponding Notebook is executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check whether new repositories and /or publications are required\n",
    "# and run the corresponding harvester\n",
    "if 'new_repositories' in params['rsidentifier']:\n",
    "    %run repository_harvester.ipynb\n",
    "if 'new_publications' in params['rsidentifier']:\n",
    "    %run publication_harvester.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Look up DOIs in the Repositories**  \n",
    "One main criterium for research software is a referenced DOI.\n",
    "Therefore, the gathered research software candidates are reviewed\n",
    "for a DOI or shortDOI by iterating over the Repositories database table.\n",
    "The extraction  is done by the auxiliary function extract_doi, that returns\n",
    "a list of DOIs. If the list is empty, the repository is not assumed to be a\n",
    "research software repository and is not inserted into the rsRepositories\n",
    "database table. All other repositories receive an entry in this database table.\n",
    "If a repository has already an entry in the database table, its reference list\n",
    "is updated. Each found DOI is inserted to the rsPublications database table with\n",
    "the provoking repository in its list of repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'dois' in params['rsidentifier']:\n",
    "\n",
    "    total = repo_table.get_number_of_entries({})\n",
    "    counter = 0\n",
    "    print('Started extracting DOIs ...')\n",
    "\n",
    "    for repo in repo_table.get_entries({}):\n",
    "\n",
    "        # progress indicator\n",
    "        counter = counter + 1\n",
    "        if counter % 500 == 0 or counter == total:\n",
    "            clear_output(wait=True)\n",
    "            print(\"processed {0} of {1}\".format(counter, total))\n",
    "\n",
    "        dois = []\n",
    "        elems = []\n",
    "\n",
    "        # look up DOI references in the repository description if exists\n",
    "        if repo['description']:\n",
    "            elems = elems + aux.extract_doi(repo['description'])\n",
    "        # look up DOI references in the repository Readme file\n",
    "        if repo['readme']:\n",
    "            elems = elems + aux.extract_doi(repo['readme'])\n",
    "\n",
    "        if not elems:\n",
    "            continue\n",
    "        # remove duplicates and add id type\n",
    "        for elem in list(set(elems)):\n",
    "            dois.append({'id': elem, 'mode': 'doi'})\n",
    "\n",
    "        # add repository to rsRepositories database table\n",
    "        rs_repo_table.save_repo(repo['id'],\n",
    "                                repo['full_name'],\n",
    "                                dois,\n",
    "                                repo['source'],\n",
    "                                repo['source'],\n",
    "                                repo['language'])\n",
    "\n",
    "        # add DOIs to rsPublications database table\n",
    "        rs_publication_table.save_publication(dois,\n",
    "                                              repo['full_name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Add Repository Names from Publications***  \n",
    "The repository names are extracted from the provided text fragments\n",
    "(Publications database table) and inserted to the rsRepositories and\n",
    "rsPublications database tables. If an entry for a repository already exists,\n",
    "the publication id is added to its reference list. The same is done for\n",
    "the publication entry, with the difference that the repository name is added\n",
    "to the repository list of the entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'repo_name' in params['rsidentifier']:\n",
    "\n",
    "    # regular expression for a full repository name in a GitHub URL\n",
    "    PATTERN_REPO = r'(?i)github\\.com/ ?([a-z0-9][a-z0-9-]*/[a-z0-9_\\.-]+)'\n",
    "\n",
    "    counter = 0\n",
    "    total = publication_table.get_number_of_entries({})\n",
    "    fragments = ['summary', 'full_text_extract', 'summary_detail', 'arxiv_comment']    \n",
    "    print('Started extracting repository names ...')\n",
    "\n",
    "    for pub in publication_table.get_entries({}):\n",
    "\n",
    "        # progress indicator\n",
    "        counter = counter + 1\n",
    "        if counter % 500 == 0 or counter == total:\n",
    "            clear_output(wait=True)\n",
    "            print(\"Processed {0} of {1}\".format(counter, total))\n",
    "        repos = []\n",
    "\n",
    "        # find GitHub repository names in the available text fragments\n",
    "        for fragment in [frag for frag in fragments if frag in pub]:\n",
    "            repos.extend(name for name in re.findall(PATTERN_REPO,\n",
    "                                                     pub[fragment])\n",
    "                         if name not in repos)\n",
    "\n",
    "        # add repositories to the research software database tables\n",
    "        for repo in repos:\n",
    "            # add information to rsRepositories\n",
    "            ident = aux.create_reference_entry(pub, True)\n",
    "            rs_repo_table.save_repo(None,\n",
    "                                    repo,\n",
    "                                    [ident],\n",
    "                                    'github',\n",
    "                                    pub['source'])\n",
    "\n",
    "            # add information to rsPublications\n",
    "            rs_publication_table.save_publication([ident], repo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add Repositories of linked Owners**   \n",
    "Besides repositories, in the publications are also repository \n",
    "owners referenced (https://github.com/{owner}). For these owners\n",
    "all their repositories are requested and added to the database table.\n",
    "This is done in two separate steps to prevent MongoDB cursor timeouts, \n",
    "request owner names twice, and to have access points for the start after \n",
    "intended and unintended breaks. Initially, the owner names are extracted \n",
    "and stored in a dictionary, together with the information of the associated publication\n",
    "and a flag whether this user is already added to the database table. \n",
    "To avoid losing the dictionary data, the following two cells ought to be \n",
    "executed one after the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'user_name' in params['rsidentifier']:\n",
    "\n",
    "    # regular expression for a repository owner in a GitHub URL\n",
    "    PATTERN_USER = r'(?i)github\\.com/ ?([a-z0-9][a-z0-9-]*)/?(?:\\s|\\.|\\)|\\'|\\\"|$|\\]|\\;|\\}|\\,)'\n",
    "\n",
    "    total = publication_table.get_number_of_entries({})\n",
    "    fragments = ['summary', 'full_text_extract', 'summary_detail', 'arxiv_comment']\n",
    "    counter = 0\n",
    "    remaining_requests = -1\n",
    "    next_url = None\n",
    "    owners = {}\n",
    "    print('Started extracting user names...')\n",
    "\n",
    "    for pub in publication_table.get_entries({}):\n",
    "\n",
    "        # progress indicator\n",
    "        counter = counter + 1\n",
    "        if counter % 500 == 0 or counter == total:\n",
    "            clear_output(wait=True)\n",
    "            print(\"processed {0} of {1}\".format(counter, total))\n",
    "        \n",
    "        users = []\n",
    "\n",
    "        # find GitHub repository owner names in the avaliable text fragments\n",
    "        for fragment in [frag for frag in fragments if frag in pub]:\n",
    "            users.extend(name for name in re.findall(PATTERN_USER,\n",
    "                                                     pub[fragment])\n",
    "                         if name not in users)\n",
    "\n",
    "        for user in users:\n",
    "            owners.update({user : {'publication': pub, 'harvested': False}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'user_name' in params['rsidentifier']:\n",
    "\n",
    "    counter = 0\n",
    "    total = len(owners)\n",
    "    # list of GitHub site names whose github link equals a valid owner link\n",
    "    github_sites = ['explore', 'topics', 'trending', 'collections', 'events',\n",
    "                    'features', 'join', 'login', 'search', 'about', 'showcases', \n",
    "                    'marketplace']\n",
    "    print('Started harvesting repositories of the given user names...')\n",
    "\n",
    "    for user, infos in owners.items():\n",
    "        if not infos['harvested']:\n",
    "\n",
    "            # progress indicator\n",
    "            counter = counter + 1\n",
    "            if counter % 25 == 0 or counter == total:\n",
    "                clear_output(wait=True)\n",
    "                print(\"processed {0} of {1}\".format(counter, total))\n",
    "        \n",
    "            # check if user candidate is one of the GitHub site names\n",
    "            if user in github_sites:\n",
    "                continue\n",
    "            # instantiate the harvester class of the repository hosting service\n",
    "            # to get all repositories of a user\n",
    "            current = getattr(\n",
    "                sys.modules[__name__],\n",
    "                params['supported_sources']['github']['class'])(params['authentication']['github'])\n",
    "            \n",
    "            while True:\n",
    "                # request repositories\n",
    "                response, remaining_requests = current.get_api_response(\n",
    "                    'user',\n",
    "                    user,\n",
    "                    remaining_requests,\n",
    "                    next_url)\n",
    "                # no valid user\n",
    "                if not response:\n",
    "                    break\n",
    "                for repo in response.json():\n",
    "                    repo_table.save_repo(repo, 'github.com', 'github', datetime.now())\n",
    "                    ident = aux.create_reference_entry(infos['publication'], True)\n",
    "                    rs_repo_table.save_repo(repo['id'],\n",
    "                                            repo['full_name'],\n",
    "                                            [ident],\n",
    "                                            'github',\n",
    "                                            infos['publication']['source'],\n",
    "                                            repo['language'])\n",
    "                    # check if current publication is in rsPublications database table\n",
    "                    rs_publication_table.save_publication([ident],\n",
    "                                                          repo['full_name'])\n",
    "                \n",
    "                # check whether further pages are available, and if so set next request url\n",
    "                if 'link' in response.headers:\n",
    "                    next_url = current.get_next_page(response.headers['link'].split(\",\"))\n",
    "                else:\n",
    "                    next_url = None\n",
    "                time.sleep(current.get_core_sleep_time())\n",
    "            \n",
    "                if not next_url:\n",
    "                    break\n",
    "            owners[user]['harvested'] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Request Metadata**  \n",
    "When requesting the repositories of an owner, the repository metadata are also provided within the API response. However, this does not apply for the extraction of the repository names from the publications text fragments. Here, only the repository name with its associated publication is added to the research software repositories database table. To confirm the repository names and simultanously harvest their metadata, for each repository the metadata are requested by the API of its hosting service.   \n",
    "Via the regular expression not always the exact name is extracted, for instance, the name may end with a full stop or a closing bracket. So, if a 404 is returned from the API, the suffix of the name is checked and non alphanumeric characters are removed, as well as some specific words, like .git, .The, or meta. Then the shortened repository name is requested.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'metadata' in params['rsidentifier']:\n",
    "\n",
    "    remaining_requests = -1\n",
    "    total = rs_repo_table.get_number_of_entries({})\n",
    "    counter = 0\n",
    "    print('Started requesting repository metadata ...')\n",
    "\n",
    "    for repo in rs_repo_table.get_entries({}):\n",
    "        reject = True\n",
    "\n",
    "        # progress indicator\n",
    "        counter = counter + 1\n",
    "        if counter % 100 == 0 or counter == total:\n",
    "            clear_output(wait=True)\n",
    "            print(\"processed {0} of {1}\".format(counter, total))\n",
    "\n",
    "        # if repo metadata already requested, continue with next repo\n",
    "        repo_meta = repo_table.get_entry({'full_name': repo['full_name']})\n",
    "        if repo_meta:\n",
    "            # check whether returned id already is in rs_repo_table\n",
    "            # if so, merge reference lists and remove duplicate entry\n",
    "            if not rs_repo_table.merge_duplicates(repo_meta, repo) and not repo['id']:\n",
    "                rs_repo_table.mod_entry({'_id':repo['_id']}, {'$set':{'id': repo_meta['id']}})\n",
    "            continue\n",
    "\n",
    "        # instantiate harvester class\n",
    "        current = getattr(\n",
    "            sys.modules[__name__],\n",
    "            params['supported_sources'][repo['source']]['class'])(params['authentication'][repo['source']])\n",
    "\n",
    "        name = repo['full_name']\n",
    "        while name:\n",
    "            response, remaining_requests = current.get_api_response(\n",
    "                'metadata', \n",
    "                name, \n",
    "                remaining_requests)\n",
    "            time.sleep(current.get_core_sleep_time())\n",
    "\n",
    "            # repository has metadata\n",
    "            if response and response.json():\n",
    "                repo_table.save_repo(response.json(), 'github.com',\n",
    "                                     repo['source'], datetime.now())\n",
    "                # check whether returned id exists already in db table\n",
    "                if not rs_repo_table.merge_duplicates(response.json(), repo):\n",
    "                    rs_repo_table.mod_entry(\n",
    "                        {'_id': repo['_id']},\n",
    "                        {'$set':\n",
    "                         {'id': response.json()['id'],\n",
    "                          'full_name': response.json()['full_name'],\n",
    "                          'language': response.json()['language']}})\n",
    "                reject = False\n",
    "                break\n",
    "            # repository does not exist, check whether the last char\n",
    "            # is not alphanumeric\n",
    "            name = aux.check_name_suffix(name)\n",
    "            meta_repo = repo_table.get_entry({'full_name':name})\n",
    "            if meta_repo:\n",
    "                # check whether returned id already is in rs_repo_table\n",
    "                # if so, merge reference lists and remove duplicate entry\n",
    "                if not rs_repo_table.merge_duplicates(meta_repo, repo) and not repo['id']:\n",
    "                    rs_repo_table.mod_entry({'_id':repo['_id']}, {'$set':{'id': meta_repo['id']}})\n",
    "                reject = False\n",
    "                break\n",
    "        if reject:\n",
    "            rs_repo_table.remove_entry({'_id':repo['_id']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check Content of Repositories**  \n",
    "Research Software contains source code. Therefore, repositories, without an assigned language and only consisting of Readme, License, and .gitignore files, are excluded from further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'content' in params['rsidentifier']:\n",
    "\n",
    "    remaining_requests = -1\n",
    "    total = rs_repo_table.get_number_of_entries(\n",
    "        {'$and': [\n",
    "            {'checked_content':{'$exists':False}},\n",
    "            {'language':None}]})\n",
    "    counter = 0\n",
    "    print('Started checking repository content...')\n",
    "\n",
    "    for repo in rs_repo_table.get_entries(\n",
    "        {'$and': [\n",
    "            {'checked_content':{'$exists':False}},\n",
    "            {'language':None}]}):\n",
    "\n",
    "        # progress indicator\n",
    "        counter = counter + 1\n",
    "        if counter % 50 == 0 or counter == total:\n",
    "            clear_output(wait=True)\n",
    "            print(\"processed {0} of {1}\".format(counter, total))\n",
    "\n",
    "        reject = True\n",
    "\n",
    "        # instantiate harvester class\n",
    "        current = getattr(\n",
    "            sys.modules[__name__],\n",
    "            params['supported_sources'][repo['source']]['class'])(params['authentication'][repo['source']])\n",
    "        reject = False\n",
    "\n",
    "        name = repo['full_name']\n",
    "        while name:\n",
    "            reject, remaining_requests = current.has_no_possible_source_code_files(\n",
    "                name,\n",
    "                remaining_requests)\n",
    "            time.sleep(current.get_core_sleep_time())\n",
    "            if not reject:\n",
    "                rs_repo_table.mod_entry(\n",
    "                    {'_id': repo['_id']},\n",
    "                    {'$set': {'full_name': name, 'checked_content':True}})\n",
    "                reject = False\n",
    "                break\n",
    "\n",
    "            # repository does not exist, check whether the last char\n",
    "            # is not alphanumeric\n",
    "            name = aux.check_name_suffix(name)\n",
    "            if rs_repo_table.get_entry({'full_name':name}):\n",
    "                break\n",
    "        if reject:\n",
    "            rs_repo_table.remove_entry({'_id':repo['_id']}) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Request the Commit Dates**   \n",
    "For the computation of the sustainability indicators, the lifespan and the activity status, the first and the last commit of a repository are required. These are no constituents of the metadate and therefore, need to be requested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'commits' in params['rsidentifier']:\n",
    "\n",
    "    total = rs_repo_table.get_number_of_entries({'first_commit':{\"$exists\" : False}})\n",
    "    remaining_requests = -1\n",
    "    counter = 0\n",
    "    print('Started harvesting first commit dates...')\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # progress indicator\n",
    "        counter = counter + 1\n",
    "        if counter % 25 == 0 or counter == total:\n",
    "            clear_output(wait=True)\n",
    "            print(\"processed {0} of {1}\".format(counter, total))\n",
    "\n",
    "        repo = rs_repo_table.get_entry({'first_commit':{\"$exists\" : False}})\n",
    "        if not repo:\n",
    "            break\n",
    "\n",
    "        current = getattr(\n",
    "            sys.modules[__name__],\n",
    "            params['supported_sources'][repo['source']]['class'])(params['authentication'][repo['source']])\n",
    "        reject, first_commit, last_commit, remaining_requests = current.get_first_commit(\n",
    "            repo['full_name'],\n",
    "            remaining_requests)\n",
    "        if reject:\n",
    "            rs_repo_table.remove_entry({'full_name':repo['full_name']})\n",
    "            continue\n",
    "\n",
    "        first = datetime.strptime(first_commit, '%Y-%m-%dT%H:%M:%SZ')\n",
    "        last = datetime.strptime(last_commit, '%Y-%m-%dT%H:%M:%SZ')\n",
    "        lifespan = (last - first).days\n",
    "        dt = (datetime.now()-relativedelta(years=1))\n",
    "        live = last >= dt\n",
    "\n",
    "        post ={\"$set\" : {\n",
    "            \"first_commit\": first_commit,\n",
    "            'last_commit': last_commit,\n",
    "            \"live\": live,\n",
    "            \"lifespan\": lifespan\n",
    "            }}\n",
    "        rs_repo_table.mod_entry({'_id': repo['_id']}, post)\n",
    "        time.sleep(current.get_core_sleep_time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Request DOI Metadata**  \n",
    "For the determination of the research area of a repository, the subject of its associated publications has to be identified. For publications the DOI metadata contain an ISSN, by that the subject of the journal, book, or conference proceeding may be looked up in the next step. Also in this case, via the regular expression not always the correct DOI is extracted. If a 404 is returned by the Crossref API the last non alphanumeric characters are cutted off and the DOI is checked again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'crossref' in params['rsidentifier']:\n",
    "\n",
    "    if 'crossref' in params['authentication']:\n",
    "        header = params['authentication']['crossref']\n",
    "    else:\n",
    "        header = None\n",
    "\n",
    "    total = rs_publication_table.get_number_of_entries(\n",
    "        {'$and': [\n",
    "            {'identifier.mode': 'doi'}, \n",
    "            {'checked_doi': {'$exists': False}}]})\n",
    "    remaining_requests = -1\n",
    "    counter = 0\n",
    "    print('Started gathering DOI metadata...')\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            pub = rs_publication_table.get_entry(\n",
    "                {'$and': [\n",
    "                    {'identifier.mode': 'doi'},\n",
    "                    {'checked_doi': {'$exists': False}}]})\n",
    "        except:\n",
    "            rs_publication_table = db.RsPublicationCollection()\n",
    "            print(\"DB reconnect ...\")\n",
    "            continue\n",
    "\n",
    "        if not pub:\n",
    "            break\n",
    "\n",
    "        # progress indicator\n",
    "        counter = counter + 1\n",
    "        if counter % 50 == 0 or counter == total:\n",
    "            clear_output(wait=True)\n",
    "            print(\"processed {0} of {1}\".format(counter, total))\n",
    "\n",
    "        present_in_db = False\n",
    "\n",
    "        doi = pub['identifier']['id']\n",
    "        last_doi = ''\n",
    "        # check whether metadata for the given DOI may be gathered\n",
    "        # for responses unequal to 200, the DOI name is truncated \n",
    "        # if it is not ending on an alphanumeric char\n",
    "        while doi:\n",
    "            call = 'https://api.crossref.org/works/' + doi\n",
    "            response = requests.get(call, headers=header)\n",
    "            \n",
    "            # response from load balancer when the service is under heavy load\n",
    "            if response.status_code in [503, 504]:\n",
    "                time.sleep(60)\n",
    "                continue\n",
    "               \n",
    "            if response.status_code == 200:\n",
    "                break\n",
    "            \n",
    "            # check whether an alias exists\n",
    "            query = 'https://doi.org/api/handles/' + doi\n",
    "            reply = requests.get(query)\n",
    "            if reply.status_code == 200:\n",
    "                alias = [elem['data']['value'] \n",
    "                         for elem in reply.json()['values'] \n",
    "                         if elem['type'] == 'HS_ALIAS']\n",
    "                if alias and last_doi != alias[0]:\n",
    "                    last_doi = doi\n",
    "                    doi = alias[0]\n",
    "                    continue\n",
    "            \n",
    "            doi = aux.check_name_suffix(doi)\n",
    "            if rs_publication_table.get_entry({'identifier.id':doi}):\n",
    "                present_in_db = True\n",
    "                break\n",
    "\n",
    "        # the truncated version of the DOI is already in the database table\n",
    "        if present_in_db:\n",
    "            rs_publication_table.remove_entry({'identifier.id': pub['identifier']['id']})\n",
    "            ident = None\n",
    "            update_repos = True\n",
    "\n",
    "        # metadata are gathered, if DOI is truncated, it is updated in the database tables\n",
    "        elif response.status_code == 200:\n",
    "            rs_publication_table.mod_entry({'_id': pub['_id']}, {'$set': response.json()['message']})\n",
    "            rs_publication_table.mod_entry({'_id': pub['_id']}, {'$set': {'checked_doi': True}})\n",
    "            update_repos = False\n",
    "            if doi != pub['identifier']['id']:\n",
    "                rs_publication_table.mod_entry({'_id': pub['_id']}, {'$set': {'identifier.id': doi}})\n",
    "                ident = {'id': doi, 'mode': 'doi'}\n",
    "                update_repos = True\n",
    "        else:\n",
    "            rs_publication_table.mod_entry({'_id': pub['_id']}, {'$set': {'checked_doi': True}})\n",
    "            update_repos = False\n",
    "        \n",
    "        if update_repos:\n",
    "            # remove unidentifiable DOI in the repositories reference list\n",
    "            # and replace it with an arxiv id or a title, if available\n",
    "            for repo in rs_repo_table.get_entries({ 'references.id': {'$eq' : pub['identifier']['id']}}):\n",
    "                rs_repo_table.update_doi(repo['_id'], pub['identifier']['id'], ident)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Journal Subject**   \n",
    "For publications with a given DOI the journal subject is specified via\n",
    "the ISSN and the Journal_Subject database table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'subject' in params['rsidentifier']:\n",
    "    \n",
    "    publication_subjects_table = db.Collection('publication_subjects')\n",
    "\n",
    "    total = rs_repo_table.get_number_of_entries(\n",
    "        {'$and':\n",
    "         [{'checked_subject': {'$exists': False}},\n",
    "          {'references.mode':'doi'}]})\n",
    "    remaining_requests = -1\n",
    "    counter = 0\n",
    "    not_found = 0\n",
    "    print('Started looking up referenced publication subject...')\n",
    "\n",
    "\n",
    "    while True:        \n",
    "        repo = rs_repo_table.get_entry({'$and':\n",
    "                        [{'checked_subject': {'$exists': False}},\n",
    "                         {'references.mode':'doi'}]})\n",
    "        if not repo:\n",
    "            break\n",
    "\n",
    "        # progress indicator\n",
    "        counter = counter + 1\n",
    "        if counter % 100 == 0 or counter == total:\n",
    "            clear_output(wait=True)\n",
    "            print(\"processed {0} of {1}\".format(counter, total))\n",
    "\n",
    "        for ref in repo['references']:\n",
    "            pub = rs_publication_table.get_entry({'identifier.id':ref['id']})\n",
    "            queries = []\n",
    "            \n",
    "            if pub:\n",
    "                if 'ISSN' in pub:\n",
    "                    for issn in pub['ISSN']:                        \n",
    "                        queries.append({'$or':\n",
    "                                        [{'print_issn': issn.replace('-','')},\n",
    "                                         {'e_issn':issn.replace('-','')}]})\n",
    "\n",
    "                elif 'ISBN' in pub:\n",
    "                    for isbn in pub['ISBN']:\n",
    "                        queries.append({'$or':\n",
    "                                        [{'print_isbn': isbn},\n",
    "                                         {'e_isbn':isbn}]})\n",
    "\n",
    "                elif 'container-title' in pub:\n",
    "                    for title in pub['container-title']:\n",
    "                        queries.append({'$or':\n",
    "                             [{'title': title},\n",
    "                              {'conference_name':title}]})\n",
    "                if queries:\n",
    "                    for query in queries:\n",
    "                        subject = publication_subjects_table.get_entry(query)\n",
    "                        if subject:\n",
    "                            rs_publication_table.mod_entry({'_id':pub['_id']},\n",
    "                                                           {'$set':\n",
    "                                                            {'sub_subject': subject['subgroups'] if 'subgroups' in subject else [None],\n",
    "                                                             'subject_asjc': subject['groups'],\n",
    "                                                             'main_subject': subject['supergroup']\n",
    "                                                            }})\n",
    "                            rs_repo_table.save_subject(repo['_id'], subject)\n",
    "        rs_repo_table.mod_entry({'_id': repo['_id']}, {'$set': {'checked_subject': True}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**arXiv Subjects**   \n",
    "arXiv provides its own category taxonomy and returns a primary category information with the search results for each publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'subject_arxiv' in params['rsidentifier']:\n",
    "    \n",
    "    arxiv_subjects_table = db.Collection('arxiv_subjects')\n",
    "\n",
    "    total = rs_repo_table.get_number_of_entries(\n",
    "        {'$and':[{'group':{'$in':['arxiv']}},\n",
    "                 {'main_subject':{'$exists':False}}]})\n",
    "    remaining_requests = -1\n",
    "    counter = 0\n",
    "    not_found = 0\n",
    "    print('Started looking up arxiv publication subjects ...')\n",
    "\n",
    "    for repo in rs_repo_table.get_entries(\n",
    "        {'$and':[{'group':{'$in':['arxiv']}},\n",
    "                 {'main_subject':{'$exists':False}}]}): \n",
    "\n",
    "        # progress indicator\n",
    "        counter = counter + 1\n",
    "        if counter % 100 == 0 or counter == total:\n",
    "            clear_output(wait=True)\n",
    "            print(\"processed {0} of {1}\".format(counter, total))\n",
    "        for ref in repo['references']:\n",
    "            \n",
    "            query = {'doi':ref['id']} if ref['mode'] == 'doi' else {'arxiv_id':ref['id']}\n",
    "\n",
    "            pub = publication_table.get_entry(query)\n",
    "\n",
    "            if pub and 'primary_category' in pub:\n",
    "                subject = arxiv_subjects_table.get_entry({'short': pub['primary_category']})\n",
    "                if subject:\n",
    "                    rs_repo_table.save_subject(repo['_id'], subject)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_final",
   "language": "python",
   "name": "venv_final"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
